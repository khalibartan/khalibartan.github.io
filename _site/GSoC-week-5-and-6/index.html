<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--><!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--><!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--><!--[if gt IE 8]><!--><html class="no-js">
<!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> <title>Google Summer of Code week 5 and 6 – Utkarsh's Blog</title> <meta name="description" content="My personal blog"> <meta name="keywords" content="pgmpy, GSoC"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="http://khalibartan.github.io/img/avatar.jpg"> <meta name="twitter:title" content="Google Summer of Code week 5 and 6"> <meta name="twitter:description" content="During week 5, I started working on No U Turn Sampler (NUTS). NUTS is an extension of Hamiltonian Monte Carlo that eliminates the need to set trajectory length. NUTS recursively builds a tree in forward and backward direction proposing set of likely candidates for new value of position and momentum and stopping automatically when it proposed values are no longer useful (doubling back).During week 6 apart from working on NUTS with dual-averaging I also used profiling to see scope of optimizations in my current implementation."> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="Google Summer of Code week 5 and 6"> <meta property="og:description" content="During week 5, I started working on No U Turn Sampler (NUTS). NUTS is an extension of Hamiltonian Monte Carlo that eliminates the need to set trajectory length. NUTS recursively builds a tree in forward and backward direction proposing set of likely candidates for new value of position and momentum and stopping automatically when it proposed values are no longer useful (doubling back).During week 6 apart from working on NUTS with dual-averaging I also used profiling to see scope of optimizations in my current implementation."> <meta property="og:url" content="http://khalibartan.github.io/GSoC-week-5-and-6/"> <meta property="og:site_name" content="Utkarsh's Blog"> <meta property="og:image" content="http://khalibartan.github.io/img/avatar.jpg"> <link rel="canonical" href="http://khalibartan.github.io/GSoC-week-5-and-6/"> <link href="http://khalibartan.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Utkarsh's Blog Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://khalibartan.github.io/assets/css/main.css"> <!-- JS --> <script src="http://khalibartan.github.io/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="http://khalibartan.github.io/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://khalibartan.github.io/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://khalibartan.github.io/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://khalibartan.github.io/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://khalibartan.github.io/favicon.png"> <link rel="shortcut icon" href="http://khalibartan.github.io/favicon.ico"> <!-- Background Image --> <style type="text/css">body {background-image:url(http://khalibartan.github.io/assets/img/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://khalibartan.github.io/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://khalibartan.github.io/img/avatar.jpg" alt="Utkarsh's Blog photo" class="author-photo"> <h4>Utkarsh's Blog</h4> <p>My personal blog</p> </li> <li><a href="http://khalibartan.github.io/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="mailto:utkarsh.gupta550@gail.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> <li> <a href="http://plus.google.com/+UtkarshGupta_khalibartan" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-google-plus-square"></i> Google+</a> </li> <li> <a href="http://linkedin.com/in/utgup" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a> </li> <li> <a href="http://github.com/khalibartan" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> </ul>
<!-- /.dl-submenu --> </li> <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="http://khalibartan.github.io/posts/">All Posts</a></li> <li><a href="http://khalibartan.github.io/tags/">All Tags</a></li> </ul> </li> <li><a href="http://khalibartan.github.io/projects/">Projects</a></li> </ul>
<!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>Google Summer of Code week 5 and 6</h1> <h4>04 Jul 2016</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~3 minutes </p>
<!-- /.entry-reading-time --> <a class="btn zoombtn" href="http://khalibartan.github.io/posts/"> <i class="fa fa-chevron-left"></i> </a> </div> <p>Mid-terms results are out. Congratulations! to all fellow GSoCer’s who successfully made it through the first half. My PR <a href="https://github.com/pgmpy/pgmpy/pull/702">#702</a> has been merged which dealt with the first half of my proposed project. During week 5, I started working on No U Turn Sampler (NUTS). NUTS is an extension of Hamiltonian Monte Carlo that eliminates the need to set trajectory length. NUTS recursively builds a tree in forward and backward direction proposing set of likely candidates for new value of position and momentum and stopping automatically when it proposed values are no longer useful (doubling back). With dual-averaging algorithm stepsize can be adapted on fly, thus making possible to <em>run NUTS without any hand tuning at all</em> :) .</p> <p>I tried implementing following algorithms from the paper[1] - Algorithm 3: Efficient No-U-Turn Sampler - Algorithm 6: No-U-Turn Sampler with Dual Averaging</p> <p>The proposed API is similar to what we have for Hamiltonian Monte Carlo. Here is a sample example on how to use NUTS</p> <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pgmpy.inference.continuous</span> <span class="kn">import</span> <span class="n">NoUTurnSampler</span> <span class="k">as</span> <span class="n">NUTS</span><span class="p">,</span> <span class="n">LeapFrog</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">JointGaussianDistribution</span> <span class="k">as</span> <span class="n">JGD</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">JGD</span><span class="p">([</span><span class="s">'x'</span><span class="p">,</span> <span class="s">'y'</span><span class="p">,</span> <span class="s">'z'</span><span class="p">],</span> <span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sampler</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">simulate_dynamics</span><span class="o">=</span><span class="n">LeapFrog</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span><span class="n">stepsize</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">samples</span>
<span class="n">rec</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
 <span class="p">(</span><span class="o">-</span><span class="mf">0.27303886844752756</span><span class="p">,</span> <span class="mf">0.5028580705249155</span><span class="p">,</span> <span class="mf">0.2895768065049909</span><span class="p">),</span>
 <span class="p">(</span><span class="mf">1.7139810571103862</span><span class="p">,</span> <span class="mf">2.809135711303245</span><span class="p">,</span> <span class="mf">5.690811523613858</span><span class="p">),</span> <span class="o">...</span><span class="p">,</span>
 <span class="p">(</span><span class="o">-</span><span class="mf">0.7742669710786649</span><span class="p">,</span> <span class="mf">2.092867703984895</span><span class="p">,</span> <span class="mf">6.139480724333439</span><span class="p">),</span>
 <span class="p">(</span><span class="mf">1.3916152816323692</span><span class="p">,</span> <span class="mf">1.394952482021687</span><span class="p">,</span> <span class="mf">3.446906546649354</span><span class="p">),</span>
 <span class="p">(</span><span class="o">-</span><span class="mf">0.2726336476939125</span><span class="p">,</span> <span class="mf">2.6230854954595357</span><span class="p">,</span> <span class="mf">2.923948403903159</span><span class="p">)],</span> 
          <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s">'x'</span><span class="p">,</span> <span class="s">'&lt;f8'</span><span class="p">),</span> <span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="s">'&lt;f8'</span><span class="p">),</span> <span class="p">(</span><span class="s">'z'</span><span class="p">,</span> <span class="s">'&lt;f8'</span><span class="p">)])</span>
</code></pre></div> <p>and NUTS with dual averaging ~~~python »&gt; from pgmpy.inference.continuous import NoUTurnSamplerDA as NUTSda »&gt; from pgmpy.models import JointGaussianDistribution as JGD »&gt; import numpy as np »&gt; mean = np.array([-1, 12, -3]) »&gt; covariance = np.array([[-2, 7, 2], [7, 14, 4], [2, 4, -1]]) »&gt; model = JGD([‘x’, ‘v’, ‘t’], mean, covariance) »&gt; sampler = NUTSda(model=model) »&gt; samples = sampler.sample(initial_pos=np.array([0, 0, 0]), num_adapt=10, num_samples=10, stepsize=0.25) »&gt; samples rec.array([(0.0, 0.0, 0.0), (0.06100992691638076, -0.17118088764170125, 0.14048470935160887), (0.06100992691638076, -0.17118088764170125, 0.14048470935160887), (-0.7451883138013118, 1.7975387358691155, 2.3090698721374436), (-0.6207457594500309, 1.4611049498441024, 2.5890867012835574), (0.24043604780911487, 1.8660976216530618, 3.2508715592645347), (0.21509819341468212, 2.157760225367607, 3.5749582768731476), (0.20699150582681913, 2.0605044285377305, 3.8588980251618135), (0.20699150582681913, 2.0605044285377305, 3.8588980251618135), (0.085332419611991, 1.7556171374575567, 4.49985082288814)], dtype=[(‘x’, ‘&lt;f8’), (‘v’, ‘&lt;f8’), (‘t’, ‘&lt;f8’)]) ~~~</p> <p>Performance wise NUTS is slower than a fine tuned HMC method for a simple model like Joint Gaussian Distribution where gradients are easy to compute because of increased number of inner products. Also in terms of memory efficiency NUTS requires to store more values of position and momentum during recursion (when we recursively build the tree). But for complex models and models with large data(high dimensionality) NUTS is really faster than tuned HMC method.</p> <p>During week 6 apart from working on NUTS with dual-averaging I also used profiling to see scope of optimizations in my current implementation. Profiling results weren’t helpful. I’ll try to think of different ways on how I can reduce number of gradient computations by re-using them.</p> <p>For the next week I’ll write tests for NUTS and NUTS with dual-averaging.</p> <h2 id="references-and-links">References and Links</h2> <ul> <li> <p>[1] <a href="http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf">Matthew D. Hoffman, Andrew Gelman: Journal of Machine Learning Research 15 (2014) 1351-1381; Algorithm 5: Hamiltonian Monte Carlo with dual-averaging</a></p> </li> <li> <p>[2] <a href="https://github.com/pgmpy/pgmpy/pull/706">Pull request for NUTS</a></p> </li> </ul> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="http://khalibartan.github.io/tags/#pgmpy" title="Pages tagged pgmpy" class="tag"><span class="term">pgmpy</span></a><a href="http://khalibartan.github.io/tags/#GSoC" title="Pages tagged GSoC" class="tag"><span class="term">GSoC</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=http://khalibartan.github.io/GSoC-week-5-and-6/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Like</span> </a> <a href="https://twitter.com/intent/tweet?text=http://khalibartan.github.io/GSoC-week-5-and-6/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> <a href="https://plus.google.com/share?url=http://khalibartan.github.io/GSoC-week-5-and-6/" title="Share on Google+" class="tag"> <span class="term"><i class="fa fa-google-plus-square"></i> +1</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> <script type="text/javascript"> var disqus_shortname = 'khalibartangithubio'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript> </header> <!-- JS --> <script src="http://khalibartan.github.io/assets/js/jquery-1.12.0.min.js"></script> <script src="http://khalibartan.github.io/assets/js/jquery.dlmenu.min.js"></script> <script src="http://khalibartan.github.io/assets/js/jquery.goup.min.js"></script> <script src="http://khalibartan.github.io/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://khalibartan.github.io/assets/js/jquery.fitvid.min.js"></script> <script src="http://khalibartan.github.io/assets/js/scripts.js"></script> <script type="text/javascript"> var disqus_shortname = 'khalibartangithubio'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
